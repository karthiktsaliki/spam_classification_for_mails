{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX,trainY,testX,testY = preprocess.input_data('./data/ham','./data/spam',.1)  \n",
    "np.savetxt(\"./data/trainX.csv\", trainX, delimiter=\",\")\n",
    "np.savetxt(\"./data/trainY.csv\", trainY, delimiter=\",\")\n",
    "np.savetxt(\"./data/testX.csv\", testX, delimiter=\",\")\n",
    "np.savetxt(\"./data/testY.csv\", testY, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_numpy_array(filePath, delimiter):\n",
    "    return np.genfromtxt(filePath, delimiter=delimiter, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "print(\"loading training data\")\n",
    "trainX = csv_to_numpy_array(\"./data/trainX.csv\", delimiter=\",\")\n",
    "trainY = csv_to_numpy_array(\"./data/trainY.csv\", delimiter=\",\")\n",
    "print(\"loading test data\")\n",
    "testX = csv_to_numpy_array(\"./data/testX.csv\", delimiter=\",\")\n",
    "testY = csv_to_numpy_array(\"./data/testY.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numFeatures = trainX.shape[1]\n",
    "numLabels = trainY.shape[1]\n",
    "numEpochs = 100\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=trainX.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=(np.sqrt(6/numFeatures+\n",
    "                                                         numLabels+1)),\n",
    "                                       name=\"weights\"))\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=(np.sqrt(6/numFeatures+numLabels+1)),\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_OP = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_values=[]\n",
    "accuracy_values=[]\n",
    "cost_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init_OP)\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "all_summary_OPS = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.287863\n",
      "step 0, cost 1595.39\n",
      "step 0, change in cost 1595.39\n",
      "step 10, training accuracy 0.712137\n",
      "step 10, cost 966.983\n",
      "step 10, change in cost 628.403\n",
      "step 20, training accuracy 0.711923\n",
      "step 20, cost 955.069\n",
      "step 20, change in cost 11.9142\n",
      "step 30, training accuracy 0.711923\n",
      "step 30, cost 952.269\n",
      "step 30, change in cost 2.80005\n",
      "step 40, training accuracy 0.711923\n",
      "step 40, cost 949.812\n",
      "step 40, change in cost 2.45642\n",
      "step 50, training accuracy 0.711923\n",
      "step 50, cost 947.419\n",
      "step 50, change in cost 2.39294\n",
      "step 60, training accuracy 0.711923\n",
      "step 60, cost 945.077\n",
      "step 60, change in cost 2.34247\n",
      "step 70, training accuracy 0.711923\n",
      "step 70, cost 942.783\n",
      "step 70, change in cost 2.29401\n",
      "step 80, training accuracy 0.711923\n",
      "step 80, cost 940.536\n",
      "step 80, change in cost 2.24628\n",
      "step 90, training accuracy 0.712137\n",
      "step 90, cost 938.336\n",
      "step 90, change in cost 2.20068\n"
     ]
    }
   ],
   "source": [
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: trainX, yGold: trainY})\n",
    "        # Report occasional stats\n",
    "        if i % 10 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            summary_results, train_accuracy, newCost = sess.run(\n",
    "                [all_summary_OPS, accuracy_OP, cost_OP], \n",
    "                feed_dict={X: trainX, yGold: trainY}\n",
    "            )\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Write summary stats to writer\n",
    "            writer.add_summary(summary_results, i)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            print(\"step %d, cost %g\"%(i, newCost))\n",
    "            print(\"step %d, change in cost %g\"%(i, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy on test set: 0.696325\n"
     ]
    }
   ],
   "source": [
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, feed_dict={X: testX, yGold: testY})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
